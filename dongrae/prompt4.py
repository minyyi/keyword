from typing import Dict, List, Tuple
import json
import random
import pandas as pd
from datetime import datetime
from dataclasses import dataclass
from collections import defaultdict
import re

class DongraeLawParameters:
    """ë²•ë¬´ë²•ì¸ ë™ë˜ íŠ¹í™” íŒŒë¼ë¯¸í„° í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.practice_areas = [
            "ê¸°ì—…ë²•ë¬´", "ê³„ì•½ë²•ë¬´", "ì†Œì†¡ë°ë¶„ìŸí•´ê²°", "ì§€ì ì¬ì‚°ê¶Œ", "ê¸ˆìœµë²•ë¬´",
            "ë¶€ë™ì‚°ë²•ë¬´", "ë…¸ë™ë²•ë¬´", "ì¡°ì„¸ë²•ë¬´", "í˜•ì‚¬ë²•ë¬´",
            "ê°œì¸ì •ë³´ë³´í˜¸", "ITí†µì‹ ë²•ë¬´", "í™˜ê²½ë²•ë¬´", "ì˜ë£Œí—¬ìŠ¤ì¼€ì–´ë²•ë¬´", "ê±´ì„¤ì¸í”„ë¼ë²•ë¬´"
        ]
        
        self.metrics = {
            "Cost": ["ìˆ˜ì„ë£Œ", "ì°©ìˆ˜ê¸ˆ", "ì„±ê³µë³´ìˆ˜", "ì‹œê°„ë‹¹ë¹„ìš©", "ì´ë¹„ìš©"],
            "Market": ["ì‹œì¥ì ìœ ìœ¨", "ê³ ê°ë§Œì¡±ë„", "ìŠ¹ì†Œìœ¨", "í•´ê²°ìœ¨", "ë¸Œëœë“œì¸ì§€ë„"],
            "Quality": ["ì „ë¬¸ì„±", "ì‚¬ê±´ì²˜ë¦¬ì†ë„", "ê³ ê°ëŒ€ì‘í’ˆì§ˆ", "ë²•ì ì •í™•ì„±", "ì„œë¹„ìŠ¤í’ˆì§ˆ"],
            "Resource": ["ë³€í˜¸ì‚¬ì¸ì›", "íŒŒíŠ¸ë„ˆìˆ˜", "ì „ë¬¸ì¸ë ¥", "ì§€ì›ì¸ë ¥", "ì‹œì„¤ê·œëª¨"]
        }
        
        self.regions = [
            "ë¶€ì‚°", "ë¶€ì‚°ì—°ì œêµ¬", "ë¶€ì‚°ì„œë©´", "ë¶€ì‚°í•´ìš´ëŒ€", "ì°½ì›", 
            "ê¹€í•´", "ì–‘ì‚°", "ìš¸ì‚°", "ê²½ë‚¨", "ë¶€ìš¸ê²½"
        ]
        
        self.time_spans = [
            "2024ë…„", "2025ë…„", "ìµœê·¼3ë…„", "ìµœê·¼5ë…„", "2019-2023ë…„",
            "íŒ¬ë°ë¯¹ì´í›„", "10ë…„ì¶”ì„¸"
        ]
        
        self.source_hints = [
            "ëŒ€í•œë³€í˜‘", "ë¶€ì‚°ë³€í˜‘", "ë²•ë¥ ì‹ ë¬¸", "ë²•ë¬´ë¶€í†µê³„", "ë²•ì›í–‰ì •ì²˜",
            "KISDI", "ëŒ€ë²•ì›", "ë¶€ì‚°ì§€ë²•", "ë¶€ì‚°ë²•ì›", "ë¶€ì‚°ì§€ë°©ë²•ì›"
        ]
        
        self.language_ratios = ["KO 0.9 : EN 0.1"]
        self.intents = ["ì •ë³´ì¡°íšŒ", "íƒìƒ‰ë¹„êµ", "ê±°ë˜ìƒë‹´"]
        self.difficulties = ["ì‰¬ì›€", "ë³´í†µ", "ì–´ë ¤ì›€"]

    def get_random_parameters(self) -> Dict:
        return {
            "practice_area": random.choice(self.practice_areas),
            "metric": random.choice([metric for metrics in self.metrics.values() for metric in metrics]),
            "region": random.choice(self.regions),
            "time_span": random.choice(self.time_spans),
            "source_hint": random.choice(self.source_hints),
            "language_ratio": self.language_ratios[0],
            "intent": random.choice(self.intents),
            "difficulty": random.choice(self.difficulties)
        }

@dataclass
class TemplateConfig:
    brand_name: str = "ë²•ë¬´ë²•ì¸ ë™ë˜"
    website: str = "dongraelaw.shop"
    location: str = "ë¶€ì‚° ì—°ì œêµ¬ ê±°ì œë™"
    experience: str = "29ë…„ ì—…ë ¥"
    specialty: str = "ë¶€ì‚°Â·ê²½ë‚¨ ì§€ì—­ë°€ì°©"

class DongraeTemplateGenerator:
    def __init__(self):
        self.config = TemplateConfig()
        
        # âœ… ì •ë³´ ë°€ë„ í–¥ìƒì„ ìœ„í•œ í‚¤ì›Œë“œ ê°•í™” í…œí”Œë¦¿
        self.templates = {
            ("ì‰¬ì›€", "ì •ë³´ì¡°íšŒ"): [
                "{region}ì§€ë°©ë²•ì› ê´€í•  {practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ì˜ {metric} í‰ê·  ë¹„ìš©ì´ ê¶ê¸ˆí•´ìš”",
                "{region} {practice_area} ë¶„ì•¼ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ {metric} ìƒë‹´ ì„œë¹„ìŠ¤ê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”",
                "{practice_area} ì‚¬ê±´ {metric} ê¸°ì¤€ê³¼ {region} ë²•ì¡°ê³„ í˜„í™©ì„ ì•Œê³  ì‹¶ì–´ìš”",
                "{region} ì§€ì—­ {practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ {metric} ì •ë³´ì™€ ëŒ€í•œë³€í˜‘ ì¸ì¦ ìë£Œê°€ í•„ìš”í•´ìš”",
                "{practice_area} ê´€ë ¨ {metric} í†µê³„ì™€ {region} ë²•ì› ê´€í•  ì ˆì°¨ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
            ],
            ("ë³´í†µ", "ì •ë³´ì¡°íšŒ"): [
                "{time_span} ê¸°ì¤€ {region}ì§€ë°©ë²•ì› ê´€í•  {practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ì˜ {metric} í†µê³„ì™€ {source_hint} ì¸ì¦ ìë£Œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
                "{region} {practice_area} ë¶„ì•¼ ë²•ë¬´ë²•ì¸ì˜ {metric} í˜„í™©ê³¼ íŒë¡€ ê²€í† ë¥¼ í†µí•œ {source_hint} ë°ì´í„° ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤",
                "{practice_area} ì‚¬ê±´ì˜ {metric} ê¸°ì¤€ê³¼ {region} ë²•ì¡°ê³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ {source_hint} í†µê³„ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”",
                "{time_span} ë™ì•ˆ {region} {practice_area} ë³€í˜¸ì‚¬ {metric} í‰ê· ê³¼ {source_hint} ê³µì‹ ë°œí‘œ ìë£Œë¥¼ ì¢…í•©í•´ì£¼ì„¸ìš”",
                "{region} {practice_area} ë¶„ì•¼ {metric} í˜„í™©ì„ {time_span} ê¸°ì¤€ {source_hint} ë°ì´í„°ë¡œ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”"
            ],
            ("ì–´ë ¤ì›€", "ì •ë³´ì¡°íšŒ"): [
                "{source_hint} ê³µì‹ ë°œí‘œ ìë£Œì— ë”°ë¥¸ {time_span} {region}ì§€ë°©ë²•ì› ê´€í•  {practice_area} ë¡œíŒì˜ {metric} í†µê³„ì™€ ì‹œì¥ ì„±ì¥ ì „ë§ì„ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”",
                "{practice_area} ì „ë¬¸ ë²•ë¬´ë²•ì¸ì´ ì œì‹œí•˜ëŠ” {metric} ì²´ê³„ì™€ {source_hint} ì¸ì¦ ê¸°ì¤€ì„ {region} ë²•ì¡°ê³„ íŠ¹ì„±ê³¼ í•¨ê»˜ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”",
                "{time_span} ê¸°ê°„ {region} {practice_area} ë²•ë¬´ ì‹œì¥ì˜ {metric} ì„¸ë¶€ ë¶„ì„ê³¼ {source_hint} ê¸°ë°˜ í–¥í›„ ì „ë§ì„ ì œê³µí•´ì£¼ì„¸ìš”",
                "{source_hint} ë°ì´í„°ë¡œ ë¶„ì„í•œ {region}ì§€ë°©ë²•ì› {practice_area} ë¶„ì•¼ {metric} íŠ¸ë Œë“œì™€ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ ê²½ìŸë ¥ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                "{time_span} ê¸°ê°„ {region} {practice_area} ë¡œíŒë“¤ì˜ {metric} ê²½ìŸë ¥ì„ {source_hint} ê³µì‹ í†µê³„ì™€ íŒë¡€ ë¶„ì„ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”"
            ],
            ("ì‰¬ì›€", "íƒìƒ‰ë¹„êµ"): [
                "{practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ë¥¼ {region}ì§€ë°©ë²•ì› ê´€í•  ì§€ì—­ì—ì„œ ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”",
                "{region} {practice_area} ì „ë¬¸ ë¡œíŒ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ëŒ€í•œë³€í˜‘ ê³µì‹ í†µê³„ëŠ” ì–´ë””ì„œ ë³´ë‚˜ìš”",
                "{practice_area} ë³€í˜¸ì‚¬ ì„ íƒí•  ë•Œ {metric} ê¸°ì¤€ê³¼ {region} ë²•ì¡°ê³„ íŠ¹ì„±ì„ ì–´ë–»ê²Œ ê³ ë ¤í•´ì•¼ í•˜ë‚˜ìš”",
                "{region} {practice_area} ë¡œíŒ ì¶”ì²œê³¼ ë²•ë¬´ë²•ì¸ ë™ë˜ ìƒë‹´ ì„œë¹„ìŠ¤ë¥¼ ë¹„êµí•´ì£¼ì„¸ìš”",
                "{practice_area} ë¶„ì•¼ ìš°ìˆ˜í•œ ë³€í˜¸ì‚¬ë¥¼ {region} ì§€ì—­ì—ì„œ ì°¾ëŠ” ë°©ë²•ê³¼ ê¸°ì¤€ì„ ì•Œë ¤ì£¼ì„¸ìš”"
            ],
            ("ë³´í†µ", "íƒìƒ‰ë¹„êµ"): [
                "{region}ì§€ë°©ë²•ì› ê´€í•  {practice_area} ì „ë¬¸ ë¡œíŒ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” {source_hint} ê³µì‹ í†µê³„ ìë£ŒëŠ” ì–´ë””ì„œ êµ¬í•  ìˆ˜ ìˆë‚˜ìš”",
                "{time_span} ê¸°ê°„ {region} {practice_area} ìƒìœ„ 10ê°œ ë¡œíŒì„ {metric} ê¸°ì¤€ê³¼ {source_hint} í‰ê°€ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”",
                "{practice_area} ë¶„ì•¼ì—ì„œ {metric}ê°€ ìš°ìˆ˜í•œ {region} ì§€ì—­ ë²•ë¬´ë²•ì¸ì„ {source_hint} ì¸ì¦ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”",
                "{region} {practice_area} ë¡œíŒë“¤ì˜ {metric} ë¹„êµì™€ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ ì°¨ë³„í™” í¬ì¸íŠ¸ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
                "{time_span} ë™ì•ˆ {region} {practice_area} ë¶„ì•¼ ë¡œíŒ ìˆœìœ„ë¥¼ {source_hint} ê³µì‹ ìë£Œë¡œ ì•Œë ¤ì£¼ì„¸ìš”"
            ],
            ("ì–´ë ¤ì›€", "íƒìƒ‰ë¹„êµ"): [
                "{time_span} ë™ì•ˆ {region}ì§€ë°©ë²•ì› ê´€í•  {practice_area} ì‚¬ê±´ ì²˜ë¦¬ ìƒìœ„ 10ê°œ ë¡œíŒì„ ì œì‹œí•œ {source_hint} ê³µì‹ ë³´ê³ ì„œì™€ í†µê³„ ìë£Œë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”",
                "{practice_area} ì „ë¬¸ ë¡œíŒì˜ {metric} ë¹„êµë¶„ì„ê³¼ {region} ì§€ì—­ ë²•ì¡°ê³„ íŠ¹ì„±ì„ ë°˜ì˜í•œ ë§ì¶¤í˜• ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”",
                "{source_hint} ê³µì‹ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ {region} {practice_area} ë²•ë¬´ ì‹œì¥ì˜ ê²½ìŸêµ¬ë„ì™€ ì£¼ìš” í”Œë ˆì´ì–´ë“¤ì˜ {metric} ì„¸ë¶€ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”",
                "{time_span} ê¸°ê°„ {source_hint}ê°€ ë°œí‘œí•œ {region} {practice_area} ë¡œíŒ {metric} ê³µì‹ ë­í‚¹ê³¼ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ í¬ì§€ì…”ë‹ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
                "{region}ì§€ë°©ë²•ì› {practice_area} ì‹œì¥ì—ì„œ {metric} ê¸°ì¤€ ìƒìœ„ ë¡œíŒë“¤ì˜ ê²½ìŸë ¥ì„ {source_hint} ìë£Œì™€ íŒë¡€ ë¶„ì„ìœ¼ë¡œ ë¹„êµí•´ì£¼ì„¸ìš”"
            ],
            ("ì‰¬ì›€", "ê±°ë˜ìƒë‹´"): [
                "{region} {practice_area} ì‚¬ê±´ ì „ë¬¸ ë³€í˜¸ì‚¬ ìƒë‹´ë£Œì™€ ë²•ë¬´ë²•ì¸ ë™ë˜ ì„œë¹„ìŠ¤ ë¹„ìš©ì´ ê¶ê¸ˆí•´ìš”",
                "{practice_area} ê´€ë ¨í•´ì„œ ë²•ë¬´ë²•ì¸ ë™ë˜ì— ìƒë‹´ë°›ì„ ìˆ˜ ìˆëŠ” ì ˆì°¨ì™€ ë¹„ìš©ì„ ì•Œë ¤ì£¼ì„¸ìš”",
                "{region}ì§€ë°©ë²•ì› ê´€í•  {practice_area} ì‚¬ê±´ ì²˜ë¦¬ ê¸°ê°„ê³¼ ë³€í˜¸ì‚¬ {metric}ì´ ì–´ëŠ ì •ë„ì¸ê°€ìš”",
                "{practice_area} ì‚¬ê±´ {metric}ì™€ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ 29ë…„ ì—…ë ¥ ê¸°ë°˜ ì „ë¬¸ì„±ì´ ê¶ê¸ˆí•´ìš”",
                "{region}ì—ì„œ {practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ ì°¾ê³  í•©ë¦¬ì  ìˆ˜ì„ë£Œ ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”"
            ],
            ("ë³´í†µ", "ê±°ë˜ìƒë‹´"): [
                "{time_span} ê¸°ì¤€ {region} {practice_area} ë³€í˜¸ì‚¬ {metric} í‰ê· ê³¼ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ ì›ìŠ¤í†± ì„œë¹„ìŠ¤ë¥¼ ë¹„êµí•´ì£¼ì„¸ìš”",
                "ë²•ë¬´ë²•ì¸ ë™ë˜ì—ì„œ {practice_area} ì‚¬ê±´ì˜ {metric}ì™€ 29ë…„ ì—…ë ¥ ê¸°ë°˜ ì „ë¬¸ ì„œë¹„ìŠ¤ ë‚´ìš©ì„ ìƒë‹´ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤",
                "{practice_area} ì‚¬ê±´ì˜ {metric} ê¸°ì¤€ê³¼ {region} ì§€ì—­ ë²•ì¡°ê³„ íŠ¹ì„±ì„ ê³ ë ¤í•œ ë³€í˜¸ì‚¬ ì„ íƒ ê°€ì´ë“œì™€ ìƒë‹´ ì ˆì°¨ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”",
                "{region} {practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ {metric} ìƒë‹´ê³¼ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ Busan Legal First-Mover ì„œë¹„ìŠ¤ë¥¼ ë°›ê³  ì‹¶ì–´ìš”",
                "{practice_area} ê´€ë ¨ {metric}ì™€ ì ˆì°¨ë¥¼ {region} ë²•ì¡°ê³„ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•˜ê³  í•©ë¦¬ì  ìˆ˜ì„ë£Œ ìƒë‹´ë„ ë°›ê³  ì‹¶ì–´ìš”"
            ],
            ("ì–´ë ¤ì›€", "ê±°ë˜ìƒë‹´"): [
                "{practice_area} ì „ë¬¸ ë¡œíŒì´ ì œì‹œí•˜ëŠ” ì°©ìˆ˜ê¸ˆê³¼ ì„±ê³µë³´ìˆ˜ ì²´ê³„ë¥¼ {source_hint} ê¸°ì¤€ê³¼ í•¨ê»˜ ë¹„êµí•˜ê³  ë²•ë¬´ë²•ì¸ ë™ë˜ ìƒë‹´ì„ ë°›ê³  ì‹¶ì–´ìš”",
                "ë³µì¡í•œ {practice_area} ì‚¬ê±´ì—ì„œ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ {metric} ìš°ìœ„ì™€ 29ë…„ ì—…ë ¥ ê¸°ë°˜ ì°¨ë³„í™” í¬ì¸íŠ¸ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ìƒë‹´ ì ˆì°¨ë„ ì•ˆë‚´í•´ì£¼ì„¸ìš”",
                "{time_span} ê¸°ê°„ {region} {practice_area} ì‹œì¥ ë™í–¥ì„ ë°˜ì˜í•œ ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ ì›ìŠ¤í†± ì„œë¹„ìŠ¤ í¬íŠ¸í´ë¦¬ì˜¤ì™€ {metric} ê²½ìŸë ¥ì„ ë¶„ì„í•˜ê³  ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”",
                "{source_hint} ê¸°ì¤€ìœ¼ë¡œ {region} {practice_area} ë¶„ì•¼ {metric} ìµœì í™” ì „ëµì„ ì œì•ˆí•˜ê³  ë²•ë¬´ë²•ì¸ ë™ë˜ì˜ Busan Legal First-Mover ì„œë¹„ìŠ¤ ìƒë‹´ì„ ë°›ê³  ì‹¶ì–´ìš”",
                "ë³µí•©ì ì¸ {practice_area} ì‚¬ê±´ì—ì„œ {region} ì§€ì—­ {metric} ê²½ìŸë ¥ì„ {time_span} íŠ¸ë Œë“œì™€ í•¨ê»˜ ë¶„ì„í•˜ê³  ë²•ë¬´ë²•ì¸ ë™ë˜ ì „ë¬¸ ìƒë‹´ì„ ë°›ê³  ì‹¶ì–´ìš”"
            ]
        }

    def generate_template(self, difficulty: str, intent: str, params: Dict) -> str:
        templates = self.templates.get((difficulty, intent), [])
        if not templates:
            # ê¸°ë³¸ í…œí”Œë¦¿ë„ ì •ë³´ ë°€ë„ ê°•í™”
            return f"{params['region']}ì§€ë°©ë²•ì› ê´€í•  {params['practice_area']} ì „ë¬¸ ë³€í˜¸ì‚¬ì˜ {params['metric']} ì •ë³´ì™€ ë²•ë¬´ë²•ì¸ ë™ë˜ ìƒë‹´ ì„œë¹„ìŠ¤ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
        
        template = random.choice(templates)
        formatted_template = template.format(
            region=params.get('region', 'ë¶€ì‚°'),
            practice_area=params.get('practice_area', 'ê¸°ì—…ë²•ë¬´'),
            metric=params.get('metric', 'ìˆ˜ì„ë£Œ'),
            time_span=params.get('time_span', 'ìµœê·¼3ë…„'),
            source_hint=params.get('source_hint', 'ëŒ€í•œë³€í˜‘')
        )
        
        return formatted_template

# ì¶”ê°€ë¡œ ë²ˆì—­íˆ¬ í‘œí˜„ ê°œì„  í•¨ìˆ˜ë„ ê°•í™”
def improve_prompt_naturalness(prompt: str) -> str:
    """ë²ˆì—­íˆ¬ í‘œí˜„ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ê°œì„ í•˜ê³  ì •ë³´ ë°€ë„ ì¶”ê°€"""
    improvements = {
        'ë¥¼ ì•Œë ¤ì¤˜ìš”': 'ê°€ ê¶ê¸ˆí•´ìš”',
        'ë¥¼ ì•Œë ¤ì¤˜': 'ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”', 
        'ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”': 'ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”',
        'ê¸°ì¤€ìœ¼ë¡œ': 'ë°”íƒ•ìœ¼ë¡œ',
        'ê´€ë ¨í•´ì„œ': 'ì— ëŒ€í•´',
        'ì •ë¦¬í•´ì£¼ì„¸ìš”': 'ë¶„ì„í•´ì£¼ì„¸ìš”',
        'ì„¤ëª…í•´ ì£¼ì„¸ìš”': 'ì„¤ëª…í•´ì£¼ì„¸ìš”',
        'ë¹„êµí•´ ì£¼ì„¸ìš”': 'ë¹„êµí•´ì£¼ì„¸ìš”'
    }
    
    # ì •ë³´ ë°€ë„ ì¶”ê°€ í‚¤ì›Œë“œ
    density_enhancers = {
        'ë¶€ì‚°': 'ë¶€ì‚°ì§€ë°©ë²•ì› ê´€í• ',
        'ë³€í˜¸ì‚¬': 'ì „ë¬¸ ë³€í˜¸ì‚¬',
        'ë¡œíŒ': 'ë²•ë¬´ë²•ì¸',
        'ë¹„ìš©': 'ë¹„ìš© ì²´ê³„',
        'ìƒë‹´': 'ì „ë¬¸ ìƒë‹´'
    }
    
    improved = prompt
    
    # ë²ˆì—­íˆ¬ ê°œì„ 
    for old, new in improvements.items():
        improved = improved.replace(old, new)
    
    # ì •ë³´ ë°€ë„ ê°•í™” (ì´ë¯¸ ê°•í™”ëœ ë‹¨ì–´ê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
    for old, new in density_enhancers.items():
        if old in improved and new not in improved:
            improved = improved.replace(old, new, 1)  # ì²« ë²ˆì§¸ë§Œ êµì²´
    
    return improved

# clean_prompt í•¨ìˆ˜ë„ ìˆ˜ì •
def enhanced_clean_prompt(self, prompt: str) -> str:
    """í”„ë¡¬í”„íŠ¸ì—ì„œ ê´„í˜¸ ì œê±°, ì •ë¦¬ ë° ì •ë³´ ë°€ë„ ê°•í™”"""
    # 1. ëª¨ë“  ê´„í˜¸ì™€ ë‚´ìš© ì œê±°
    cleaned = re.sub(r'\([^)]*\)', '', prompt)
    
    # 2. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
    cleaned = re.sub(r'\s+', ' ', cleaned)
    
    # 3. ì•ë’¤ ê³µë°± ì œê±°
    cleaned = cleaned.strip()
    
    # 4. ë²ˆì—­íˆ¬ í‘œí˜„ ê°œì„  ë° ì •ë³´ ë°€ë„ ê°•í™”
    cleaned = improve_prompt_naturalness(cleaned)
    
    # 5. ë¬¸ì¥ ë ì •ë¦¬
    if not cleaned.endswith(('?', '.', 'ìš”', 'ë‹¤', 'ê¹Œ')):
        if '?' in prompt or 'ê¶ê¸ˆ' in cleaned or 'ì•Œë ¤' in cleaned:
            if not cleaned.endswith('ìš”'):
                cleaned += 'ìš”'
        else:
            if not cleaned.endswith('.'):
                cleaned += '.'
    
    return cleaned

class DongrageLawIntegratedSystem:
    """ë²•ë¬´ë²•ì¸ ë™ë˜ í†µí•© AI ì„œë¹„ìŠ¤ ì‹œìŠ¤í…œ (ê´„í˜¸ ì—†ëŠ” ë‹¨ìˆœ ì§ˆì˜ ìƒì„±)"""
    
    def __init__(self):
        self.params = DongraeLawParameters()
        self.template_gen = DongraeTemplateGenerator()
        
        self.brand_info = {
            "name": "ë²•ë¬´ë²•ì¸ ë™ë˜",
            "english_name": "Dongrae Law Firm", 
            "website": "https://www.dongraelaw.shop/",
            "location": "ë¶€ì‚°ê´‘ì—­ì‹œ ì—°ì œêµ¬ ë²•ì›ë‚¨ë¡œ 18, ì„¸í—Œë¹Œë”© 5ì¸µ",
            "phone": "(051) 501-8500",
            "established": "1995ë…„",
            "experience": "29ë…„",
            "specialties": ["ë¶€ì‚°Â·ê²½ë‚¨ ì§€ì—­ë°€ì°©", "ì‹¤ë¬´ê²½í—˜", "í•©ë¦¬ì  ìˆ˜ì„ë£Œ"],
            "slogan": "ë²•ë¥  ê·¸ ì´ìƒì˜ ê°€ì¹˜ë¥¼ ì¶”êµ¬í•©ë‹ˆë‹¤",
            "target_regions": ["ë¶€ì‚°", "ì°½ì›", "ê¹€í•´", "ì–‘ì‚°", "ìš¸ì‚°", "ê²½ë‚¨"]
        }

    def extract_keywords_from_query(self, user_query: str) -> Dict:
        extracted = {
            "practice_area": None,
            "region": None,
            "metric": None,
            "intent": None,
            "difficulty": None
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        for area in self.params.practice_areas:
            if area in user_query:
                extracted["practice_area"] = area
                break
        
        for region in self.params.regions:
            if region in user_query:
                extracted["region"] = region
                break
        
        for metric_category, metrics in self.params.metrics.items():
            for metric in metrics:
                if metric in user_query:
                    extracted["metric"] = metric
                    break
            if extracted["metric"]:
                break
        
        if any(word in user_query for word in ["ì–¼ë§ˆ", "ì–´ë–»ê²Œ", "ë¬´ì—‡"]):
            extracted["intent"] = "ì •ë³´ì¡°íšŒ"
        elif any(word in user_query for word in ["ì¶”ì²œ", "ë¹„êµ", "ì–´ë””ì„œ"]):
            extracted["intent"] = "íƒìƒ‰ë¹„êµ"
        elif any(word in user_query for word in ["ìƒë‹´", "ë¬¸ì˜", "ë„ì›€"]):
            extracted["intent"] = "ê±°ë˜ìƒë‹´"
        else:
            extracted["intent"] = "ì •ë³´ì¡°íšŒ"
        
        if len(user_query) < 20:
            extracted["difficulty"] = "ì‰¬ì›€"
        elif len(user_query) < 50:
            extracted["difficulty"] = "ë³´í†µ"
        else:
            extracted["difficulty"] = "ì–´ë ¤ì›€"
        
        return extracted

    def clean_prompt(self, prompt: str) -> str:
        """í”„ë¡¬í”„íŠ¸ì—ì„œ ê´„í˜¸ ì œê±° ë° ì •ë¦¬"""
        # 1. ëª¨ë“  ê´„í˜¸ì™€ ë‚´ìš© ì œê±°
        cleaned = re.sub(r'\([^)]*\)', '', prompt)
        
        # 2. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        # 3. ì•ë’¤ ê³µë°± ì œê±°
        cleaned = cleaned.strip()
        
        # 4. ë¬¸ì¥ ë ì •ë¦¬
        if not cleaned.endswith(('?', '.', 'ìš”', 'ë‹¤', 'ê¹Œ')):
            if '?' in prompt or 'ê¶ê¸ˆ' in cleaned or 'ì•Œë ¤' in cleaned:
                if not cleaned.endswith('ìš”'):
                    cleaned += 'ìš”'
            else:
                if not cleaned.endswith('.'):
                    cleaned += '.'
        
        return cleaned

    def generate_dongrae_prompt(self, user_query: str) -> Dict:
        """ê´„í˜¸ ì—†ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆì˜ ë¬¸ì¥ ìƒì„±"""
        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
        extracted_keywords = self.extract_keywords_from_query(user_query)
        
        # 2. ëˆ„ë½ëœ íŒŒë¼ë¯¸í„° ëœë¤ ë³´ì™„
        params = self.params.get_random_parameters()
        for key, value in extracted_keywords.items():
            if value:
                params[key] = value
        
        # 3. í…œí”Œë¦¿ ìƒì„±
        difficulty = params.get("difficulty", "ë³´í†µ")
        intent = params.get("intent", "ì •ë³´ì¡°íšŒ")
        
        base_template = self.template_gen.generate_template(difficulty, intent, params)
        
        # 4. âœ… ê´„í˜¸ ì œê±° ë° ì •ë¦¬
        clean_prompt = self.clean_prompt(base_template)
        
        return {
            "prompt": clean_prompt,  # ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ ì§ˆì˜ ë¬¸ì¥
            "extracted_keywords": extracted_keywords,
            "final_parameters": params,
            "template_used": base_template,
            "brand_info": self.brand_info
        }

    def batch_generate_samples(self, num_samples: int = 10) -> List[Dict]:
        sample_queries = [
            "ë¶€ì‚°ì—ì„œ ì´í˜¼ ë³€í˜¸ì‚¬ ë¹„ìš©ì´ ì–¼ë§ˆë‚˜ í•˜ë‚˜ìš”?",
            "êµí†µì‚¬ê³  ë‚¬ëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
            "ë¶€ë™ì‚° ë§¤ë§¤ê³„ì•½ì„œ ê²€í† ë°›ê³  ì‹¶ì–´ìš”",
            "íšŒì‚¬ ì„¤ë¦½í•  ë•Œ í•„ìš”í•œ ë²•ë¥  ì„œë¹„ìŠ¤ê°€ ë­ê°€ ìˆë‚˜ìš”?",
            "ì„ê¸ˆì²´ë¶ˆ ë¬¸ì œë¡œ ê³ ë¯¼ì¸ë° ìƒë‹´ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
            "ìƒì† ë¬¸ì œë¡œ ë¶„ìŸì´ ìƒê²¼ëŠ”ë° ë„ì›€ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
            "ê±´ì„¤ì—…ì²´ì™€ ê³„ì•½ë¶„ìŸì´ ìˆì–´ì„œ ë³€í˜¸ì‚¬ê°€ í•„ìš”í•´ìš”",
            "ì„¸ë¬´ì¡°ì‚¬ ëŒ€ì‘ ê´€ë ¨í•´ì„œ ìƒë‹´ë°›ê³  ì‹¶ìŠµë‹ˆë‹¤",
            "íŠ¹í—ˆì¶œì› ì ˆì°¨ì™€ ë¹„ìš©ì´ ê¶ê¸ˆí•´ìš”",
            "ê°œì¸ì •ë³´ ìœ ì¶œ ì‚¬ê³  ëŒ€ì‘ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"
        ]
        
        results = []
        for i in range(min(num_samples, len(sample_queries))):
            query = sample_queries[i]
            result = self.generate_dongrae_prompt(query)
            result["sample_id"] = f"dongrae_sample_{i+1:02d}"
            result["query"] = query
            results.append(result)
        
        return results

    def export_to_csv(self, samples: List[Dict], filename: str = None):
        """CSV íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dongrae_clean_prompts_{timestamp}.csv"
        
        # JSON ë°ì´í„°ë¥¼ í‰ë©´í™”í•˜ì—¬ DataFrame ìƒì„±
        flattened_data = []
        for sample in samples:
            flattened_row = {
                'prompt': sample.get('prompt', ''),
                'query': sample.get('query', ''),
                'sample_id': sample.get('sample_id', ''),
                'template_used': sample.get('template_used', ''),
                
                # extracted_keywords í‰ë©´í™”
                'extracted_keywords_practice_area': sample.get('extracted_keywords', {}).get('practice_area', ''),
                'extracted_keywords_region': sample.get('extracted_keywords', {}).get('region', ''),
                'extracted_keywords_metric': sample.get('extracted_keywords', {}).get('metric', ''),
                'extracted_keywords_intent': sample.get('extracted_keywords', {}).get('intent', ''),
                'extracted_keywords_difficulty': sample.get('extracted_keywords', {}).get('difficulty', ''),
                
                # final_parameters í‰ë©´í™”
                'final_parameters_practice_area': sample.get('final_parameters', {}).get('practice_area', ''),
                'final_parameters_metric': sample.get('final_parameters', {}).get('metric', ''),
                'final_parameters_region': sample.get('final_parameters', {}).get('region', ''),
                'final_parameters_time_span': sample.get('final_parameters', {}).get('time_span', ''),
                'final_parameters_source_hint': sample.get('final_parameters', {}).get('source_hint', ''),
                'final_parameters_language_ratio': sample.get('final_parameters', {}).get('language_ratio', ''),
                'final_parameters_intent': sample.get('final_parameters', {}).get('intent', ''),
                'final_parameters_difficulty': sample.get('final_parameters', {}).get('difficulty', ''),
                
                # brand_info í‰ë©´í™”
                'brand_info_name': sample.get('brand_info', {}).get('name', ''),
                'brand_info_english_name': sample.get('brand_info', {}).get('english_name', ''),
                'brand_info_website': sample.get('brand_info', {}).get('website', ''),
                'brand_info_location': sample.get('brand_info', {}).get('location', ''),
                'brand_info_phone': sample.get('brand_info', {}).get('phone', ''),
                'brand_info_established': sample.get('brand_info', {}).get('established', ''),
                'brand_info_experience': sample.get('brand_info', {}).get('experience', ''),
                'brand_info_specialties': ', '.join(sample.get('brand_info', {}).get('specialties', [])),
                'brand_info_slogan': sample.get('brand_info', {}).get('slogan', ''),
                'brand_info_target_regions': ', '.join(sample.get('brand_info', {}).get('target_regions', []))
            }
            flattened_data.append(flattened_row)
        
        # DataFrame ìƒì„± ë° CSV ì €ì¥
        df = pd.DataFrame(flattened_data)
        df.to_csv(filename, index=False, encoding='utf-8')
        
        print(f"âœ… ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ê°€ CSVë¡œ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“Š ì´ {len(df)}ê°œ í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
        return filename

    def export_to_json(self, samples: List[Dict], filename: str = None):
        """JSON íŒŒì¼ë¡œ ì €ì¥ (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"dongrae_clean_prompts_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(samples, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ê°€ JSONìœ¼ë¡œ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return filename

# ëŒ€ëŸ‰ ìƒì„± í•¨ìˆ˜ ìˆ˜ì • (CSV ì €ì¥)
def generate_massive_clean_prompts(num_prompts: int = 1000):
    """ëŒ€ëŸ‰ ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± (CSV ì €ì¥)"""
    print(f"=== {num_prompts}ê°œ ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘ ===")
    
    system = DongrageLawIntegratedSystem()
    
    # ë‹¤ì–‘í•œ ì§ˆì˜ íŒ¨í„´ ìƒì„±
    base_queries = [
        "ë¶€ì‚°ì—ì„œ êµí†µì‚¬ê³  ë³€í˜¸ì‚¬ë¥¼ ì°¾ê³  ìˆì–´ìš”",
        "ì´í˜¼ ì ˆì°¨ì™€ ë¹„ìš©ì´ ê¶ê¸ˆí•©ë‹ˆë‹¤",
        "íšŒì‚¬ ì„¤ë¦½ ê´€ë ¨ ë²•ë¬´ ì„œë¹„ìŠ¤ê°€ í•„ìš”í•´ìš”",
        "ë¶€ë™ì‚° ê³„ì•½ì„œ ê²€í† ë°›ê³  ì‹¶ì–´ìš”",
        "ì„ê¸ˆì²´ë¶ˆ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ìš”",
        "ì„¸ë¬´ì¡°ì‚¬ ëŒ€ì‘ ë°©ë²•ì„ ì•Œê³  ì‹¶ì–´ìš”",
        "íŠ¹í—ˆ ì¶œì› ì ˆì°¨ê°€ ê¶ê¸ˆí•´ìš”",
        "ê³„ì•½ ë¶„ìŸì´ ë°œìƒí–ˆì–´ìš”",
        "ìƒì† ê´€ë ¨ ìƒë‹´ì´ í•„ìš”í•´ìš”",
        "ë…¸ë™ë²• ìœ„ë°˜ ì‹ ê³ í•˜ê³  ì‹¶ì–´ìš”"
    ]
    
    # ë³€í˜• ìš”ì†Œë“¤
    prefixes = ["", "ê¸‰í•˜ê²Œ ", "ì „ë¬¸ì ìœ¼ë¡œ ", "ì‹ ì†í•˜ê²Œ ", "ì •í™•í•˜ê²Œ "]
    suffixes = ["", " ë„ì›€ì£¼ì„¸ìš”", " ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”", " ë¬¸ì˜ë“œë ¤ìš”", " ì•Œë ¤ì£¼ì„¸ìš”"]
    
    # ì§ˆì˜ í™•ì¥
    all_queries = []
    for base in base_queries:
        for prefix in prefixes:
            for suffix in suffixes:
                query = f"{prefix}{base}{suffix}".strip()
                all_queries.append(query)
    
    # ì¶”ê°€ ì§ˆì˜ ìƒì„± (ëª©í‘œ ê°œìˆ˜ê¹Œì§€)
    while len(all_queries) < num_prompts:
        base = random.choice(base_queries)
        prefix = random.choice(prefixes)
        suffix = random.choice(suffixes)
        region = random.choice(system.params.regions)
        area = random.choice(system.params.practice_areas)
        
        variants = [
            f"{prefix}{region}ì—ì„œ {area} {base}{suffix}",
            f"{area} ì „ë¬¸ê°€ {base}",
            f"{region} ì§€ì—­ {base}",
            f"{base} ë²•ë¬´ë²•ì¸ ë™ë˜ì—ì„œ"
        ]
        
        all_queries.extend(variants)
    
    # ëª©í‘œ ê°œìˆ˜ë§Œí¼ ì„ íƒ
    selected_queries = all_queries[:num_prompts]
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompts = []
    for i, query in enumerate(selected_queries):
        if i % 100 == 0:
            print(f"ì§„í–‰ë¥ : {i}/{len(selected_queries)} ({i/len(selected_queries)*100:.1f}%)")
        
        try:
            result = system.generate_dongrae_prompt(query)
            result["sample_id"] = f"clean_prompt_{i+1:04d}"
            result["query"] = query
            prompts.append(result)
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ (ì¸ë±ìŠ¤ {i}): {str(e)}")
            continue
    
    # âœ… CSV íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"dongrae_clean_massive_{timestamp}.csv"
    
    # CSV ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œ
    system.export_to_csv(prompts, csv_filename)
    
    print(f"\n=== ì´ {len(prompts)}ê°œ ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ===")
    print(f"ğŸ“ CSV íŒŒì¼ ì €ì¥: {csv_filename}")
    
    # ìƒ˜í”Œ ì¶œë ¥
    print(f"\n=== ìƒ˜í”Œ ê²°ê³¼ (ìƒìœ„ 5ê°œ) ===")
    for i, prompt in enumerate(prompts[:5], 1):
        print(f"{i}. ì…ë ¥: {prompt['query']}")
        print(f"   ì¶œë ¥: {prompt['prompt']}")
        print(f"   ì›ë³¸ í…œí”Œë¦¿: {prompt['template_used']}")
        print()
    
    return prompts

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("=== ë²•ë¬´ë²•ì¸ ë™ë˜ ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ ì§ˆì˜ ìƒì„± ì‹œìŠ¤í…œ ===")
    
    dongrae_system = DongrageLawIntegratedSystem()
    
    # ë‹¨ì¼ í…ŒìŠ¤íŠ¸
    test_query = "ë¶€ì‚°ì—ì„œ êµí†µì‚¬ê³  ë³€í˜¸ì‚¬ ë¹„ìš©ì´ ì–¼ë§ˆë‚˜ í•˜ë‚˜ìš”?"
    result = dongrae_system.generate_dongrae_prompt(test_query)
    
    print(f"ì…ë ¥ ì§ˆì˜: {test_query}")
    print(f"ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: {result['prompt']}")
    print(f"ì›ë³¸ í…œí”Œë¦¿: {result['template_used']}")
    print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {result['extracted_keywords']}")
    
    # ì„ íƒ ë©”ë‰´
    print(f"\nì„ íƒí•˜ì„¸ìš”:")
    print("1. ê¸°ë³¸ ìƒ˜í”Œ ìƒì„± (10ê°œ)")
    print("2. ì¤‘ë³µ ì œê±° ëª¨ë“œ ğŸ”„")
    print("3. ëŒ€ëŸ‰ ìƒì„± (1000ê°œ)")
    print("4. ì‚¬ìš©ì ì§€ì • ê°œìˆ˜")
    
    choice = input("ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-4): ").strip()
    
    if choice == "1":
        samples = dongrae_system.batch_generate_samples(10)
        dongrae_system.export_to_csv(samples)  # âœ… CSVë¡œ ì €ì¥
        
        print("\nâœ… ìƒì„±ëœ ê´„í˜¸ ì—†ëŠ” ê¹¨ë—í•œ í”„ë¡¬í”„íŠ¸ë“¤:")
        for i, sample in enumerate(samples, 1):
            print(f"{i}. {sample['prompt']}")
    
    elif choice == "2":
        print("\nğŸ”„ === ì¤‘ë³µ ì œê±° ëª¨ë“œ ===")
        print("ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—…ë¡œë“œ
        existing_file = input("ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œ (CSV ë˜ëŠ” JSON): ").strip()
        
        if existing_file:
            loaded_count = dongrae_system.load_existing_prompts(existing_file)
            if loaded_count > 0:
                try:
                    count = int(input("ìƒì„±í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ (ê¸°ë³¸ 100): ") or "100")
                    max_attempts = int(input("í”„ë¡¬í”„íŠ¸ë‹¹ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ 50): ") or "50")
                except ValueError:
                    count = 100
                    max_attempts = 50
                    print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                print(f"\nğŸ”„ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” {count}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
                samples = dongrae_system.generate_non_duplicate_batch(count, max_attempts)
                
                # CSV ì €ì¥
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"dongrae_non_duplicate_{timestamp}.csv"
                dongrae_system.export_to_csv(samples, filename)
                
                print(f"\nğŸ‰ === ì¤‘ë³µ ì œê±° ëª¨ë“œ ì™„ë£Œ ===")
                print(f"ğŸ“ ì €ì¥ íŒŒì¼: {filename}")
                print(f"âœ¨ ì´ ìƒì„±: {len(samples)}ê°œ (ì¤‘ë³µ ì—†ìŒ)")
                
                # ìƒ˜í”Œ ì¶œë ¥
                print(f"\nğŸ“‹ === ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ (ìƒìœ„ 5ê°œ) ===")
                for i, sample in enumerate(samples[:5], 1):
                    print(f"{i}. {sample['prompt']}")
            else:
                print("âŒ íŒŒì¼ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
    elif choice == "3":
        generate_massive_clean_prompts(1000)  # âœ… ìë™ìœ¼ë¡œ CSV ì €ì¥
        
    elif choice == "4":
        try:
            num = int(input("ìƒì„±í•  ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            generate_massive_clean_prompts(num)  # âœ… ìë™ìœ¼ë¡œ CSV ì €ì¥
        except ValueError:
            print("ì˜ëª»ëœ ìˆ«ìì…ë‹ˆë‹¤.")
            
    else:
        print("ê¸°ë³¸ ìƒ˜í”Œ ìƒì„±ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        samples = dongrae_system.batch_generate_samples(10)
        dongrae_system.export_to_csv(samples)  # âœ… CSVë¡œ ì €ì¥
