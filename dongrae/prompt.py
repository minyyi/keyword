# ë²•ë¬´ë²•ì¸ ë™ë˜ ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°
import json
import random
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple
from itertools import product, combinations
from collections import defaultdict
import os

# ê¸°ì¡´ ì‹œìŠ¤í…œ í´ë˜ìŠ¤ë“¤ import (ì•ì„œ ë§Œë“  ì½”ë“œê°€ ìˆë‹¤ê³  ê°€ì •)
# ì—¬ê¸°ì„œëŠ” í•„ìš”í•œ ë¶€ë¶„ë§Œ ì¬ì •ì˜

class MassivePromptGenerator:
    """ë²•ë¬´ë²•ì¸ ë™ë˜ ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        # ê¸°ë³¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        from para_tem import DongrageLawIntegratedSystem
        self.dongrae_system = DongrageLawIntegratedSystem()
        
        # í™•ì¥ëœ ì§ˆì˜ í…œí”Œë¦¿ë“¤
        self.expanded_query_templates = {
            "ê¸°ì—…ë²•ë¬´": [
                "{region}ì—ì„œ {action} ê¸°ì—… ì„¤ë¦½ {detail} {urgency}",
                "ìŠ¤íƒ€íŠ¸ì—… {action} {detail} ë²•ë¬´ ì„œë¹„ìŠ¤ {metric} {urgency}",
                "M&A {action} {detail} ì „ë¬¸ ë³€í˜¸ì‚¬ {metric} {region}",
                "ì£¼ì‹íšŒì‚¬ {action} {detail} ì ˆì°¨ {metric} {urgency}",
                "íˆ¬ìê³„ì•½ì„œ {action} {detail} ê²€í†  {metric} {region}",
                "ë²•ì¸ì„¸ {action} {detail} ìë¬¸ {metric} {urgency}",
                "ì»´í”Œë¼ì´ì–¸ìŠ¤ {action} {detail} êµ¬ì¶• {metric} {region}",
                "ì£¼ì£¼ì´íšŒ {action} {detail} ìš´ì˜ {metric} {urgency}",
                "ê¸°ì—…ë¶„ìŸ {action} {detail} í•´ê²° {metric} {region}",
                "ìƒì¥ì¤€ë¹„ {action} {detail} ë²•ë¬´ {metric} {urgency}"
            ],
            
            "ê³„ì•½ë²•ë¬´": [
                "ê³„ì•½ì„œ {action} {detail} ì‘ì„± {metric} {region}",
                "ê³µê¸‰ê³„ì•½ {action} {detail} ê²€í†  {metric} {urgency}",
                "ìœ í†µê³„ì•½ {action} {detail} í˜‘ìƒ {metric} {region}",
                "ë¼ì´ì„ ìŠ¤ {action} {detail} ê³„ì•½ {metric} {urgency}",
                "í”„ëœì°¨ì´ì¦ˆ {action} {detail} ê³„ì•½ {metric} {region}",
                "ê³ ìš©ê³„ì•½ {action} {detail} ì‘ì„± {metric} {urgency}",
                "ë¹„ë°€ìœ ì§€ {action} {detail} ê³„ì•½ {metric} {region}",
                "ê³„ì•½ë¶„ìŸ {action} {detail} í•´ê²° {metric} {urgency}",
                "êµ­ì œê³„ì•½ {action} {detail} ê²€í†  {metric} {region}",
                "ê±´ì„¤ê³„ì•½ {action} {detail} ìë¬¸ {metric} {urgency}"
            ],
            
            "ì†Œì†¡ë°ë¶„ìŸí•´ê²°": [
                "ë¯¼ì‚¬ì†Œì†¡ {action} {detail} ëŒ€ë¦¬ {metric} {region}",
                "ìƒì‚¬ë¶„ìŸ {action} {detail} í•´ê²° {metric} {urgency}",
                "ì†í•´ë°°ìƒ {action} {detail} ì²­êµ¬ {metric} {region}",
                "ì±„ê¶ŒíšŒìˆ˜ {action} {detail} ì†Œì†¡ {metric} {urgency}",
                "ì¤‘ì¬ì ˆì°¨ {action} {detail} ëŒ€ë¦¬ {metric} {region}",
                "ì¡°ì •ì‹ ì²­ {action} {detail} ëŒ€ë¦¬ {metric} {urgency}",
                "ì§‘ë‹¨ì†Œì†¡ {action} {detail} ì°¸ì—¬ {metric} {region}",
                "í–‰ì •ì†Œì†¡ {action} {detail} ëŒ€ë¦¬ {metric} {urgency}",
                "êµ­ì œì¤‘ì¬ {action} {detail} ëŒ€ë¦¬ {metric} {region}",
                "ë¶€ë™ì‚°ë¶„ìŸ {action} {detail} í•´ê²° {metric} {urgency}"
            ],
            
            "ë¶€ë™ì‚°ë²•ë¬´": [
                "ë¶€ë™ì‚° {action} {detail} ë§¤ë§¤ {metric} {region}",
                "ì„ëŒ€ì°¨ {action} {detail} ë¶„ìŸ {metric} {urgency}",
                "ì „ì„¸ê³„ì•½ {action} {detail} ê²€í†  {metric} {region}",
                "ê±´ì¶•í—ˆê°€ {action} {detail} ì‹ ì²­ {metric} {urgency}",
                "ì¬ê°œë°œ {action} {detail} ë²•ë¬´ {metric} {region}",
                "ë¶€ë™ì‚°íˆ¬ì {action} {detail} ìë¬¸ {metric} {urgency}",
                "ë“±ê¸°ì—…ë¬´ {action} {detail} ëŒ€í–‰ {metric} {region}",
                "ì†Œìœ ê¶Œë¶„ìŸ {action} {detail} í•´ê²° {metric} {urgency}",
                "ë¶€ë™ì‚°ê°œë°œ {action} {detail} ë²•ë¬´ {metric} {region}",
                "ìƒê°€ì„ëŒ€ {action} {detail} ê³„ì•½ {metric} {urgency}"
            ],
            
            "ë…¸ë™ë²•ë¬´": [
                "ë¶€ë‹¹í•´ê³  {action} {detail} êµ¬ì œ {metric} {region}",
                "ì„ê¸ˆì²´ë¶ˆ {action} {detail} í•´ê²° {metric} {urgency}",
                "ê·¼ë¡œê³„ì•½ {action} {detail} ì‘ì„± {metric} {region}",
                "ì„±í¬ë¡± {action} {detail} ëŒ€ì‘ {metric} {urgency}",
                "ì‚°ì—…ì¬í•´ {action} {detail} ë³´ìƒ {metric} {region}",
                "ë…¸ë™ì¡°í•© {action} {detail} êµì„­ {metric} {urgency}",
                "í‡´ì§ê¸ˆ {action} {detail} ë¶„ìŸ {metric} {region}",
                "ì§ì¥ë‚´ê´´ë¡­í˜ {action} {detail} ì‹ ê³  {metric} {urgency}",
                "ì—°ì¥ê·¼ë¬´ {action} {detail} ìˆ˜ë‹¹ {metric} {region}",
                "4ëŒ€ë³´í—˜ {action} {detail} ìë¬¸ {metric} {urgency}"
            ],
            
            "í˜•ì‚¬ë²•ë¬´": [
                "êµí†µì‚¬ê³  {action} {detail} ë³€í˜¸ {metric} {region}",
                "ìŒì£¼ìš´ì „ {action} {detail} ë³€í˜¸ {metric} {urgency}",
                "í­í–‰ì‚¬ê±´ {action} {detail} ë³€í˜¸ {metric} {region}",
                "ì‚¬ê¸°ì‚¬ê±´ {action} {detail} ë³€í˜¸ {metric} {urgency}",
                "íš¡ë ¹ì‚¬ê±´ {action} {detail} ë³€í˜¸ {metric} {region}",
                "ì„±ë²”ì£„ {action} {detail} ë³€í˜¸ {metric} {urgency}",
                "ê²½ì œë²”ì£„ {action} {detail} ë³€í˜¸ {metric} {region}",
                "ê³ ì†Œê³ ë°œ {action} {detail} ëŒ€ë¦¬ {metric} {urgency}",
                "ìˆ˜ì‚¬ë™í–‰ {action} {detail} ì„œë¹„ìŠ¤ {metric} {region}",
                "í˜•ì‚¬í•©ì˜ {action} {detail} ì¤‘ì¬ {metric} {urgency}"
            ],
            
            "ì¡°ì„¸ë²•ë¬´": [
                "ì„¸ë¬´ì¡°ì‚¬ {action} {detail} ëŒ€ì‘ {metric} {region}",
                "ì¡°ì„¸ë¶ˆë³µ {action} {detail} ì‹ ì²­ {metric} {urgency}",
                "ìƒì†ì„¸ {action} {detail} ì‹ ê³  {metric} {region}",
                "ì¦ì—¬ì„¸ {action} {detail} ì ˆì„¸ {metric} {urgency}",
                "ë¶€ê°€ê°€ì¹˜ì„¸ {action} {detail} í™˜ê¸‰ {metric} {region}",
                "ë²•ì¸ì„¸ {action} {detail} ì‹ ê³  {metric} {urgency}",
                "ì¢…í•©ì†Œë“ì„¸ {action} {detail} ì‹ ê³  {metric} {region}",
                "êµ­ì„¸ì²­í˜‘ì˜ {action} {detail} ëŒ€ë¦¬ {metric} {urgency}",
                "ì´ì „ê°€ê²© {action} {detail} ìë¬¸ {metric} {region}",
                "êµ­ì œì¡°ì„¸ {action} {detail} ìë¬¸ {metric} {urgency}"
            ],
            
            "ì§€ì ì¬ì‚°ê¶Œ": [
                "íŠ¹í—ˆì¶œì› {action} {detail} ëŒ€ë¦¬ {metric} {region}",
                "ìƒí‘œë“±ë¡ {action} {detail} ì‹ ì²­ {metric} {urgency}",
                "ì €ì‘ê¶Œ {action} {detail} ë³´í˜¸ {metric} {region}",
                "ë””ìì¸ë“±ë¡ {action} {detail} ì‹ ì²­ {metric} {urgency}",
                "íŠ¹í—ˆì¹¨í•´ {action} {detail} ì†Œì†¡ {metric} {region}",
                "ë¼ì´ì„ ìŠ¤ {action} {detail} ê³„ì•½ {metric} {urgency}",
                "ê¸°ìˆ ì´ì „ {action} {detail} ê³„ì•½ {metric} {region}",
                "ì˜ì—…ë¹„ë°€ {action} {detail} ë³´í˜¸ {metric} {urgency}",
                "ë¸Œëœë“œë³´í˜¸ {action} {detail} ì „ëµ {metric} {region}",
                "ì§€ì¬ê¶Œë¶„ìŸ {action} {detail} í•´ê²° {metric} {urgency}"
            ]
        }
        
        # ë³€ìˆ˜ ê°’ë“¤
        self.template_variables = {
            "action": [
                "ê´€ë ¨í•´ì„œ", "ë•Œë¬¸ì—", "í•˜ë ¤ê³  í•˜ëŠ”ë°", "ë¬¸ì œë¡œ", "í•„ìš”í•´ì„œ",
                "í•˜ê³  ì‹¶ì€ë°", "ë„ì›€ì´ í•„ìš”í•œ", "ìƒë‹´ë°›ê³  ì‹¶ì€", "ì˜ë¢°í•˜ê³  ì‹¶ì€",
                "ì•Œì•„ë³´ê³  ìˆëŠ”", "ì¤€ë¹„í•˜ëŠ”", "ì§„í–‰í•˜ëŠ”", "ê³„íšì¤‘ì¸", "ê²€í† í•˜ëŠ”"
            ],
            "detail": [
                "ì „ë¬¸ì ì¸", "í•©ë¦¬ì ì¸", "ì‹ ì†í•œ", "ì •í™•í•œ", "ì²´ê³„ì ì¸",
                "ê²½í—˜ìˆëŠ”", "ë¯¿ì„ë§Œí•œ", "ì‹¤ë¬´ì ì¸", "íš¨ê³¼ì ì¸", "ì•ˆì „í•œ",
                "íˆ¬ëª…í•œ", "ì¹œì ˆí•œ", "ê¼¼ê¼¼í•œ", "ì„¸ë°€í•œ", "ì¢…í•©ì ì¸"
            ],
            "metric": [
                "ë¹„ìš©ì´ ê¶ê¸ˆí•´ìš”", "ì ˆì°¨ë¥¼ ì•Œê³  ì‹¶ì–´ìš”", "ê¸°ê°„ì´ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”",
                "ì„±ê³µë¥ ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”", "ì¤€ë¹„ì„œë¥˜ê°€ ë­ê°€ ìˆë‚˜ìš”", "ì£¼ì˜ì‚¬í•­ì´ ìˆë‚˜ìš”",
                "ì¥ë‹¨ì ì„ ì•Œë ¤ì£¼ì„¸ìš”", "ê²½í—˜ë‹´ì„ ë“¤ë ¤ì£¼ì„¸ìš”", "ì¶”ì²œí•´ì£¼ì„¸ìš”",
                "ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”", "ê²¬ì ì„ ë°›ê³  ì‹¶ì–´ìš”", "ë¬¸ì˜ë“œë ¤ìš”"
            ],
            "urgency": [
                "ê¸‰í•´ìš”", "ë¹¨ë¦¬ í•´ê²°í•´ì•¼ í•´ìš”", "ì‹œê°„ì´ ì—†ì–´ìš”", "ì˜¤ëŠ˜ ì¤‘ì— ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”",
                "ì‘ê¸‰ìƒí™©ì´ì—ìš”", "ë‚´ì¼ê¹Œì§€ í•„ìš”í•´ìš”", "ì´ë²ˆ ì£¼ ì•ˆì— í•´ê²°í•´ì•¼ í•´ìš”",
                "ì²œì²œíˆ ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”", "ê³„íšì ìœ¼ë¡œ ì¤€ë¹„í•˜ê³  ì‹¶ì–´ìš”", "ì—¬ìœ ìˆê²Œ ì§„í–‰í•˜ê³  ì‹¶ì–´ìš”"
            ],
            "region": [
                "ë¶€ì‚°ì—ì„œ", "ë¶€ì‚° ì—°ì œêµ¬ì—ì„œ", "ë¶€ì‚° í•´ìš´ëŒ€ì—ì„œ", "ë¶€ì‚° ì„œë©´ì—ì„œ",
                "ì°½ì›ì—ì„œ", "ê¹€í•´ì—ì„œ", "ì–‘ì‚°ì—ì„œ", "ìš¸ì‚°ì—ì„œ", "ê²½ë‚¨ì—ì„œ", "ë¶€ìš¸ê²½ì—ì„œ"
            ]
        }
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì§ˆì˜ íŒ¨í„´
        self.scenario_patterns = {
            "ê°œì¸_ì¼ë°˜": [
                "ê°œì¸ì ìœ¼ë¡œ {practice_area} ë¬¸ì œê°€ ìƒê²¼ëŠ”ë° ë„ì›€ë°›ì„ ìˆ˜ ìˆë‚˜ìš”?",
                "{practice_area} ê´€ë ¨í•´ì„œ ì²˜ìŒ ê²ªëŠ” ì¼ì´ë¼ ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´ìš”",
                "ì¹œêµ¬ê°€ {practice_area} ë¬¸ì œë¥¼ ê²ªê³  ìˆëŠ”ë° ì¶”ì²œí•´ì£¼ê³  ì‹¶ì–´ìš”",
                "ê°€ì¡±ì´ {practice_area} ìƒí™©ì— ì²˜í–ˆëŠ”ë° ìƒë‹´ë°›ê³  ì‹¶ì–´ìš”"
            ],
            "ê¸°ì—…_ì„ì›": [
                "ì €í¬ íšŒì‚¬ì—ì„œ {practice_area} ì´ìŠˆê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                "{practice_area} ê´€ë ¨ ê¸°ì—… ë²•ë¬´ ì„œë¹„ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "ì„ì›ì§„ ì°¨ì›ì—ì„œ {practice_area} ì „ëµì„ ìˆ˜ë¦½í•˜ê³  ìˆìŠµë‹ˆë‹¤",
                "íšŒì‚¬ ì •ì±…ìœ¼ë¡œ {practice_area} ì»´í”Œë¼ì´ì–¸ìŠ¤ë¥¼ ê°•í™”í•˜ë ¤ê³  í•©ë‹ˆë‹¤"
            ],
            "ì†Œìƒê³µì¸": [
                "ì‘ì€ ì‚¬ì—…ì„ í•˜ëŠ”ë° {practice_area} ë¬¸ì œê°€ ìƒê²¼ì–´ìš”",
                "ê°œì¸ì‚¬ì—…ìë¡œì„œ {practice_area} ê´€ë ¨ ê¶ê¸ˆí•œ ì ì´ ìˆì–´ìš”",
                "ìì˜ì—… í•˜ë©´ì„œ {practice_area} ì´ìŠˆë¥¼ ê²ªê³  ìˆì–´ìš”",
                "ì†Œê·œëª¨ ì‚¬ì—…ì²´ì—ì„œ {practice_area} ìë¬¸ì´ í•„ìš”í•´ìš”"
            ],
            "ê¸´ê¸‰ìƒí™©": [
                "ì§€ê¸ˆ ë‹¹ì¥ {practice_area} ê´€ë ¨ ì‘ê¸‰ìƒí™©ì´ì—ìš”!",
                "ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ {practice_area} ë¬¸ì œë¥¼ í•´ê²°í•´ì•¼ í•´ìš”",
                "ê¸´ê¸‰í•˜ê²Œ {practice_area} ì „ë¬¸ê°€ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "ê¸‰í•œ {practice_area} ì‚¬ì•ˆìœ¼ë¡œ ì¦‰ì‹œ ìƒë‹´ì´ í•„ìš”í•´ìš”"
            ],
            "ë¹„êµê²€í† ": [
                "ë‹¤ë¥¸ ë¡œíŒê³¼ {practice_area} ì„œë¹„ìŠ¤ë¥¼ ë¹„êµí•´ë³´ê³  ì‹¶ì–´ìš”",
                "{practice_area} ì „ë¬¸ ë³€í˜¸ì‚¬ë“¤ ì¤‘ì—ì„œ ì¶”ì²œí•´ì£¼ì„¸ìš”",
                "ì—¬ëŸ¬ ë²•ë¬´ë²•ì¸ì˜ {practice_area} ë¹„ìš©ì„ ì•Œì•„ë³´ê³  ìˆì–´ìš”",
                "{practice_area} ë¶„ì•¼ì—ì„œ í‰íŒ ì¢‹ì€ ê³³ì„ ì°¾ê³  ìˆì–´ìš”"
            ]
        }

    def generate_comprehensive_queries(self) -> List[str]:
        """ì¢…í•©ì ì¸ ì§ˆì˜ ìƒì„±"""
        all_queries = []
        
        # 1. í…œí”Œë¦¿ ê¸°ë°˜ ì§ˆì˜ ìƒì„±
        for practice_area, templates in self.expanded_query_templates.items():
            for template in templates:
                # ê° í…œí”Œë¦¿ë§ˆë‹¤ 3ê°€ì§€ ë³€í˜• ìƒì„±
                for _ in range(3):
                    query = template.format(
                        action=random.choice(self.template_variables["action"]),
                        detail=random.choice(self.template_variables["detail"]),
                        metric=random.choice(self.template_variables["metric"]),
                        urgency=random.choice(self.template_variables["urgency"]),
                        region=random.choice(self.template_variables["region"])
                    )
                    all_queries.append(query)
        
        # 2. ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ ì§ˆì˜ ìƒì„±
        for scenario, patterns in self.scenario_patterns.items():
            for pattern in patterns:
                for practice_area in self.dongrae_system.params.practice_areas:
                    query = pattern.format(practice_area=practice_area)
                    all_queries.append(query)
        
        # 3. ì‹¤ì œ ìƒí™© ê¸°ë°˜ ì§ˆì˜ ìƒì„±
        realistic_queries = [
            "ë¶€ì‚°ì—ì„œ êµí†µì‚¬ê³  ë‚¬ëŠ”ë° ìƒëŒ€ë°©ì´ í•©ì˜ë¥¼ ê±°ë¶€í•´ìš”",
            "ì´í˜¼í•˜ë ¤ëŠ”ë° ì¬ì‚°ë¶„í• ê³¼ ì–‘ìœ¡ê¶Œì´ ê±±ì •ë¼ìš”",
            "íšŒì‚¬ì—ì„œ ê°‘ìê¸° í•´ê³ í†µë³´ë¥¼ ë°›ì•˜ì–´ìš”",
            "ì„ëŒ€ì¸ì´ ë³´ì¦ê¸ˆì„ ëŒë ¤ì£¼ì§€ ì•Šì•„ìš”",
            "ì‚¬ì—…íŒŒíŠ¸ë„ˆê°€ ëˆì„ ê°€ì§€ê³  ì ì í–ˆì–´ìš”",
            "ì„¸ë¬´ì„œì—ì„œ ì¡°ì‚¬í•˜ê² ë‹¤ê³  ì—°ë½ì´ ì™”ì–´ìš”",
            "íŠ¹í—ˆ ì¹¨í•´ë¡œ ì†Œì†¡ì„ ë‹¹í–ˆì–´ìš”",
            "ê±´ì¶•ì—…ì²´ê°€ ê³µì‚¬ë¥¼ ì œëŒ€ë¡œ í•˜ì§€ ì•Šì•„ìš”",
            "ì§ì¥ì—ì„œ ì„±í¬ë¡±ì„ ë‹¹í–ˆì–´ìš”",
            "ìƒì†ë°›ì€ ë¶€ë™ì‚° ë•Œë¬¸ì— í˜•ì œë“¤ê³¼ ë¶„ìŸì´ ìƒê²¼ì–´ìš”",
            "íšŒì‚¬ ì„¤ë¦½í•˜ë ¤ëŠ”ë° ì ˆì°¨ê°€ ë³µì¡í•´ìš”",
            "ê°œì¸ì •ë³´ê°€ ìœ ì¶œë˜ì–´ì„œ í”¼í•´ë¥¼ ë´¤ì–´ìš”",
            "ìŒì£¼ìš´ì „ìœ¼ë¡œ ë‹¨ì†ë˜ì—ˆëŠ”ë° ë©´í—ˆì •ì§€ê°€ ê±±ì •ë¼ìš”",
            "ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ì°½ì—…í•˜ë ¤ëŠ”ë° ì•½ê´€ ì‘ì„±ì´ í•„ìš”í•´ìš”",
            "ê·¼ë¡œìê°€ ì‚°ì—…ì¬í•´ë¥¼ ë‹¹í–ˆì–´ìš”",
            "ìƒí‘œë¥¼ ë“±ë¡í•˜ë ¤ëŠ”ë° ê¸°ì¡´ ìƒí‘œì™€ ìœ ì‚¬í•´ìš”",
            "ê³„ì•½ì„œë¥¼ ì‘ì„±í–ˆëŠ”ë° ë¶ˆë¦¬í•œ ì¡°í•­ì´ ìˆëŠ” ê²ƒ ê°™ì•„ìš”",
            "ë¶€ë™ì‚° íˆ¬ìí•˜ë ¤ëŠ”ë° ë²•ì  ê²€í† ê°€ í•„ìš”í•´ìš”",
            "ì§ì›ì´ íšŒì‚¬ ê¸°ë°€ì„ ìœ ì¶œí–ˆì–´ìš”",
            "í”„ëœì°¨ì´ì¦ˆ ê³„ì•½ì„ ì²´ê²°í•˜ë ¤ëŠ”ë° ì¡°ê±´ì„ ê²€í† í•´ì£¼ì„¸ìš”",
            # ë¶€ì‚° ì§€ì—­ íŠ¹í™” ì§ˆì˜ë“¤
            "í•´ìš´ëŒ€ ì•„íŒŒíŠ¸ ë§¤ë§¤ê³„ì•½ ì²´ê²° ì „ì— ê²€í† ë°›ê³  ì‹¶ì–´ìš”",
            "ë¶€ì‚°í•­ ë¬¼ë¥˜ì—…ì²´ì™€ ê³„ì•½ ë¶„ìŸì´ ìƒê²¼ì–´ìš”",
            "ì„œë©´ ìƒê°€ì„ëŒ€ ê³„ì•½ ê°±ì‹ ì„ ê±°ë¶€ë‹¹í–ˆì–´ìš”",
            "ë™ë˜ì˜¨ì²œ ê´€ê´‘ì—… ê´€ë ¨ í—ˆê°€ ë¬¸ì œê°€ ìˆì–´ìš”",
            "ê´‘ì•ˆë¦¬ íœì…˜ ìš´ì˜ ì¤‘ ë¯¼ì›ì´ ë°œìƒí–ˆì–´ìš”",
            "ë¶€ì‚° ì¡°ì„ ì—…ì²´ì—ì„œ ê·¼ë¬´í•˜ë‹¤ê°€ í•´ê³ ëì–´ìš”",
            "ê¸°ì¥êµ° ë†ì§€ ì „ìš©í—ˆê°€ë¥¼ ë°›ê³  ì‹¶ì–´ìš”",
            "ì‚¬í•˜êµ¬ ê³µì¥ ì„¤ë¦½ ê´€ë ¨ í™˜ê²½í‰ê°€ê°€ í•„ìš”í•´ìš”",
            "ì˜ë„êµ¬ ì¬ê°œë°œ ê´€ë ¨ ë³´ìƒ ë¬¸ì œê°€ ìˆì–´ìš”",
            "ì—°ì œêµ¬ ë³‘ì› ê°œì„¤ í—ˆê°€ë¥¼ ë°›ê³  ì‹¶ì–´ìš”"
        ]
        
        all_queries.extend(realistic_queries)
        
        # 4. ë‚œì´ë„ë³„ ì „ë¬¸ ì§ˆì˜ ìƒì„±
        expert_queries = [
            # ê³ ë‚œì´ë„ ì§ˆì˜ë“¤
            "ë³µí•©ì ì¸ M&A ê±°ë˜ì—ì„œ ì‹¤ì‚¬(Due Diligence) ê³¼ì •ì˜ ë²•ì  ë¦¬ìŠ¤í¬ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”",
            "êµ­ì œê³„ì•½ì—ì„œ CISG ì ìš© ë°°ì œ ì¡°í•­ê³¼ ì¤€ê±°ë²• ì„ íƒì˜ ìœ íš¨ì„±ì„ ê²€í† í•´ì£¼ì„¸ìš”",
            "ìŠ¤í†¡ì˜µì…˜ ë¶€ì—¬ ì‹œ ì„¸ë¬´ìƒ ì´ìŠˆì™€ ë…¸ë™ë²•ìƒ ì œì•½ì‚¬í•­ì„ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”",
            "GDPRê³¼ ê°œì¸ì •ë³´ë³´í˜¸ë²•ì˜ ì¶©ëŒ ì‹œ í•´ê²°ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”",
            "í¬ë¡œìŠ¤ë³´ë” ì¤‘ì¬ì ˆì°¨ì—ì„œ í•œêµ­ë²•ì›ì˜ ê´€í• ê¶Œ ë¬¸ì œë¥¼ ê²€í† í•´ì£¼ì„¸ìš”",
            # ì¤‘ê°„ ë‚œì´ë„ ì§ˆì˜ë“¤
            "ë¶€ë™ì‚° ë§¤ë§¤ê³„ì•½ì˜ íŠ¹ì•½ì‚¬í•­ì´ ë²•ì ìœ¼ë¡œ ìœ íš¨í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”",
            "ê·¼ë¡œê³„ì•½ì„œì˜ ê²½ì—…ê¸ˆì§€ ì¡°í•­ì´ ê³¼ë„í•œì§€ íŒë‹¨í•´ì£¼ì„¸ìš”",
            "ìŠ¤íƒ€íŠ¸ì—… íˆ¬ìê³„ì•½ì„œì˜ í¬ì„ë°©ì§€ ì¡°í•­ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ìƒí‘œê¶Œ ì¹¨í•´ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ì„ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì„¸ë¬´ì¡°ì‚¬ ì‹œ ë‚©ì„¸ìì˜ ê¶Œë¦¬ì™€ ì˜ë¬´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        ]
        
        all_queries.extend(expert_queries)
        
        return list(set(all_queries))  # ì¤‘ë³µ ì œê±°

    def generate_massive_prompts(self, num_prompts: int = 1000) -> List[Dict]:
        """ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        print(f"=== {num_prompts}ê°œ í”„ë¡¬í”„íŠ¸ ëŒ€ëŸ‰ ìƒì„± ì‹œì‘ ===")
        
        # ëª¨ë“  ì§ˆì˜ ìƒì„±
        all_queries = self.generate_comprehensive_queries()
        print(f"ê¸°ë³¸ ì§ˆì˜ {len(all_queries)}ê°œ ìƒì„± ì™„ë£Œ")
        
        # ì¶”ê°€ ì§ˆì˜ ìƒì„± (ëª©í‘œ ê°œìˆ˜ê¹Œì§€)
        additional_needed = max(0, num_prompts - len(all_queries))
        if additional_needed > 0:
            print(f"ì¶”ê°€ ì§ˆì˜ {additional_needed}ê°œ ìƒì„± ì¤‘...")
            
            # ê¸°ì¡´ ì§ˆì˜ë¥¼ ë³€í˜•í•´ì„œ ì¶”ê°€ ìƒì„±
            for _ in range(additional_needed):
                base_query = random.choice(all_queries)
                
                # ëœë¤í•˜ê²Œ ë³€í˜• ìš”ì†Œ ì¶”ê°€
                variations = [
                    f"ê¸‰í•˜ê²Œ {base_query}",
                    f"ë¹„ìš©ì„ ìµœì†Œí™”í•´ì„œ {base_query}",
                    f"ì „ë¬¸ì ìœ¼ë¡œ {base_query}",
                    f"ì‹ ì†í•˜ê²Œ {base_query}",
                    f"ì •í™•í•˜ê²Œ {base_query}",
                    f"ì•ˆì „í•˜ê²Œ {base_query}",
                    f"ì²´ê³„ì ìœ¼ë¡œ {base_query}",
                    f"ê²½í—˜ ë§ì€ ë³€í˜¸ì‚¬ì—ê²Œ {base_query}",
                    f"ë¶€ì‚° ì§€ì—­ ì „ë¬¸ê°€ì—ê²Œ {base_query}",
                    f"ë²•ë¬´ë²•ì¸ ë™ë˜ì—ì„œ {base_query}"
                ]
                
                variation = random.choice(variations)
                all_queries.append(variation)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompts = []
        selected_queries = all_queries[:num_prompts]
        
        print(f"ì„ íƒëœ {len(selected_queries)}ê°œ ì§ˆì˜ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        
        for i, query in enumerate(selected_queries):
            if i % 100 == 0:
                print(f"ì§„í–‰ë¥ : {i}/{len(selected_queries)} ({i/len(selected_queries)*100:.1f}%)")
            
            try:
                result = self.dongrae_system.generate_dongrae_prompt(query)
                result["sample_id"] = f"dongrae_massive_{i+1:04d}"
                result["query"] = query
                result["generation_timestamp"] = datetime.now().isoformat()
                prompts.append(result)
            except Exception as e:
                print(f"ì§ˆì˜ ì²˜ë¦¬ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {i}): {str(e)}")
                continue
        
        print(f"=== ì´ {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ===")
        return prompts

    def analyze_massive_results(self, prompts: List[Dict]) -> Dict:
        """ëŒ€ëŸ‰ ìƒì„± ê²°ê³¼ ë¶„ì„"""
        analysis = {
            "total_count": len(prompts),
            "practice_area_distribution": defaultdict(int),
            "region_distribution": defaultdict(int),
            "intent_distribution": defaultdict(int),
            "difficulty_distribution": defaultdict(int),
            "metric_distribution": defaultdict(int),
            "query_length_stats": {
                "min": float('inf'),
                "max": 0,
                "avg": 0,
                "lengths": []
            },
            "template_diversity": defaultdict(int)
        }
        
        for prompt in prompts:
            params = prompt["final_parameters"]
            query = prompt["query"]
            
            # ë¶„í¬ ë¶„ì„
            analysis["practice_area_distribution"][params.get("practice_area", "ë¯¸ë¶„ë¥˜")] += 1
            analysis["region_distribution"][params.get("region", "ë¯¸ë¶„ë¥˜")] += 1
            analysis["intent_distribution"][params.get("intent", "ë¯¸ë¶„ë¥˜")] += 1
            analysis["difficulty_distribution"][params.get("difficulty", "ë¯¸ë¶„ë¥˜")] += 1
            analysis["metric_distribution"][params.get("metric", "ë¯¸ë¶„ë¥˜")] += 1
            
            # ê¸¸ì´ í†µê³„
            query_len = len(query)
            analysis["query_length_stats"]["lengths"].append(query_len)
            analysis["query_length_stats"]["min"] = min(analysis["query_length_stats"]["min"], query_len)
            analysis["query_length_stats"]["max"] = max(analysis["query_length_stats"]["max"], query_len)
            
            # í…œí”Œë¦¿ ë‹¤ì–‘ì„±
            template = prompt["template_used"][:50] + "..."  # ì• 50ìë§Œ
            analysis["template_diversity"][template] += 1
        
        # í‰ê·  ê¸¸ì´ ê³„ì‚°
        if analysis["query_length_stats"]["lengths"]:
            analysis["query_length_stats"]["avg"] = sum(analysis["query_length_stats"]["lengths"]) / len(analysis["query_length_stats"]["lengths"])
        
        return analysis

    def export_massive_results(self, prompts: List[Dict], analysis: Dict) -> Dict:
        """ëŒ€ëŸ‰ ìƒì„± ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ì „ì²´ í”„ë¡¬í”„íŠ¸ JSON ì €ì¥
        json_filename = f"dongrae_massive_prompts_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(prompts, f, ensure_ascii=False, indent=2)
        
        # 2. ë¶„ì„ ê²°ê³¼ JSON ì €ì¥
        analysis_filename = f"dongrae_analysis_{timestamp}.json"
        with open(analysis_filename, 'w', encoding='utf-8') as f:
            # defaultdictì„ ì¼ë°˜ dictìœ¼ë¡œ ë³€í™˜
            analysis_dict = {}
            for key, value in analysis.items():
                if isinstance(value, defaultdict):
                    analysis_dict[key] = dict(value)
                else:
                    analysis_dict[key] = value
            json.dump(analysis_dict, f, ensure_ascii=False, indent=2)
        
        # 3. ì§ˆì˜ë§Œ ì¶”ì¶œí•´ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        queries_filename = f"dongrae_queries_{timestamp}.txt"
        with open(queries_filename, 'w', encoding='utf-8') as f:
            for i, prompt in enumerate(prompts, 1):
                f.write(f"{i:04d}. {prompt['query']}\n")
        
        # 4. í”„ë¡¬í”„íŠ¸ë§Œ ì¶”ì¶œí•´ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        prompts_filename = f"dongrae_prompts_only_{timestamp}.txt"
        with open(prompts_filename, 'w', encoding='utf-8') as f:
            for i, prompt in enumerate(prompts, 1):
                f.write(f"=== í”„ë¡¬í”„íŠ¸ {i:04d} ===\n")
                f.write(f"ì§ˆì˜: {prompt['query']}\n")
                f.write(f"í”„ë¡¬í”„íŠ¸:\n{prompt['prompt']}\n")
                f.write("\n" + "="*50 + "\n\n")
        
        # 5. ë¶„ì„ ê²°ê³¼ ìš”ì•½ CSV ì €ì¥
        summary_data = []
        
        # ë²•ë¬´ë¶„ì•¼ë³„ í†µê³„
        for area, count in analysis["practice_area_distribution"].items():
            summary_data.append({
                "ì¹´í…Œê³ ë¦¬": "ë²•ë¬´ë¶„ì•¼",
                "í•­ëª©": area,
                "ê°œìˆ˜": count,
                "ë¹„ìœ¨": f"{count/analysis['total_count']*100:.1f}%"
            })
        
        # ì§€ì—­ë³„ í†µê³„
        for region, count in analysis["region_distribution"].items():
            summary_data.append({
                "ì¹´í…Œê³ ë¦¬": "ì§€ì—­",
                "í•­ëª©": region,
                "ê°œìˆ˜": count,
                "ë¹„ìœ¨": f"{count/analysis['total_count']*100:.1f}%"
            })
        
        # ì˜ë„ë³„ í†µê³„
        for intent, count in analysis["intent_distribution"].items():
            summary_data.append({
                "ì¹´í…Œê³ ë¦¬": "ì˜ë„",
                "í•­ëª©": intent,
                "ê°œìˆ˜": count,
                "ë¹„ìœ¨": f"{count/analysis['total_count']*100:.1f}%"
            })
        
        summary_df = pd.DataFrame(summary_data)
        summary_csv = f"dongrae_summary_{timestamp}.csv"
        summary_df.to_csv(summary_csv, index=False, encoding='utf-8-sig')
        
        print(f"\n=== íŒŒì¼ ì €ì¥ ì™„ë£Œ ===")
        print(f"1. ì „ì²´ í”„ë¡¬í”„íŠ¸: {json_filename}")
        print(f"2. ë¶„ì„ ê²°ê³¼: {analysis_filename}")
        print(f"3. ì§ˆì˜ ëª©ë¡: {queries_filename}")
        print(f"4. í”„ë¡¬í”„íŠ¸ ëª¨ìŒ: {prompts_filename}")
        print(f"5. ìš”ì•½ í†µê³„: {summary_csv}")
        
        return {
            "json_file": json_filename,
            "analysis_file": analysis_filename,
            "queries_file": queries_filename,
            "prompts_file": prompts_filename,
            "summary_file": summary_csv
        }

# ì‹¤í–‰ í•¨ìˆ˜
# ì‹¤í–‰ í•¨ìˆ˜
def run_massive_generation(num_prompts: int = 1000):
    """ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤í–‰"""
    print("=" * 60)
    print("ë²•ë¬´ë²•ì¸ ë™ë˜ ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì‹œì‘")
    print("=" * 60)
    
    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = MassivePromptGenerator()
    
    # ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompts = generator.generate_massive_prompts(num_prompts)
    
    # ê²°ê³¼ ë¶„ì„
    print("\në¶„ì„ ì¤‘...")
    analysis = generator.analyze_massive_results(prompts)
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print(f"\n=== ìƒì„± ê²°ê³¼ ë¶„ì„ ===")
    print(f"ì´ ìƒì„± ê°œìˆ˜: {analysis['total_count']:,}ê°œ")
    print(f"ì§ˆì˜ ê¸¸ì´: ìµœì†Œ {analysis['query_length_stats']['min']}ì, ìµœëŒ€ {analysis['query_length_stats']['max']}ì, í‰ê·  {analysis['query_length_stats']['avg']:.1f}ì")
    
    print(f"\nğŸ“Š ë²•ë¬´ë¶„ì•¼ ë¶„í¬:")
    for area, count in sorted(analysis["practice_area_distribution"].items(), key=lambda x: x[1], reverse=True):
        percentage = count / analysis['total_count'] * 100
        print(f"  {area}: {count}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ—ºï¸ ì§€ì—­ ë¶„í¬:")
    for region, count in sorted(analysis["region_distribution"].items(), key=lambda x: x[1], reverse=True):
        percentage = count / analysis['total_count'] * 100
        print(f"  {region}: {count}ê°œ ({percentage:.1f}%)")
    
    print(f"\nğŸ¯ ì˜ë„ ë¶„í¬:")
    for intent, count in sorted(analysis["intent_distribution"].items(), key=lambda x: x[1], reverse=True):
        percentage = count / analysis['total_count'] * 100
        print(f"  {intent}: {count}ê°œ ({percentage:.1f}%)")
    
    print(f"\nâš¡ ë‚œì´ë„ ë¶„í¬:")
    for difficulty, count in sorted(analysis["difficulty_distribution"].items(), key=lambda x: x[1], reverse=True):
        percentage = count / analysis['total_count'] * 100
        print(f"  {difficulty}: {count}ê°œ ({percentage:.1f}%)")
    
    # ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ ì¶œë ¥
    print(f"\n=== ìƒ˜í”Œ í”„ë¡¬í”„íŠ¸ (ìƒìœ„ 5ê°œ) ===")
    for i, prompt in enumerate(prompts[:5], 1):
        print(f"\n[ìƒ˜í”Œ {i}]")
        print(f"ì§ˆì˜: {prompt['query']}")
        print(f"ë¶„ì•¼: {prompt['final_parameters']['practice_area']}")
        print(f"ì§€ì—­: {prompt['final_parameters']['region']}")
        print(f"ì˜ë„: {prompt['final_parameters']['intent']}")
        print(f"ë‚œì´ë„: {prompt['final_parameters']['difficulty']}")
        print("-" * 40)
    
    # íŒŒì¼ ì €ì¥
    files = generator.export_massive_results(prompts, analysis)
    
    # ì¶”ê°€ í†µê³„ ì •ë³´
    print(f"\n=== í’ˆì§ˆ ì§€í‘œ ===")
    print(f"í…œí”Œë¦¿ ë‹¤ì–‘ì„±: {len(analysis['template_diversity'])}ê°œ ê³ ìœ  í…œí”Œë¦¿")
    print(f"í‰ê·  í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {sum(len(p['prompt']) for p in prompts) // len(prompts):,}ì")
    
    # ì§€ì—­ë³„ ë²•ë¬´ë¶„ì•¼ êµì°¨ ë¶„ì„
    print(f"\n=== ì§€ì—­ Ã— ë²•ë¬´ë¶„ì•¼ êµì°¨ ë¶„ì„ (ìƒìœ„ 10ê°œ) ===")
    cross_analysis = defaultdict(int)
    for prompt in prompts:
        params = prompt['final_parameters']
        key = f"{params.get('region', 'ë¯¸ë¶„ë¥˜')} Ã— {params.get('practice_area', 'ë¯¸ë¶„ë¥˜')}"
        cross_analysis[key] += 1
    
    for combo, count in sorted(cross_analysis.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"  {combo}: {count}ê°œ")
    
    print(f"\n=== í™œìš© ê°€ì´ë“œ ===")
    print("1. ğŸ¤– AI ëª¨ë¸ í›ˆë ¨ìš©:")
    print(f"   - {files['json_file']} íŒŒì¼ì„ AI í›ˆë ¨ ë°ì´í„°ë¡œ í™œìš©")
    print("   - ì§ˆì˜-ì‘ë‹µ ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ fine-tuning ê°€ëŠ¥")
    
    print("\n2. ğŸ“Š ì„œë¹„ìŠ¤ ê¸°íšìš©:")
    print(f"   - {files['summary_file']} íŒŒì¼ë¡œ ê³ ê° ë‹ˆì¦ˆ ë¶„ì„")
    print("   - ì§€ì—­ë³„, ë¶„ì•¼ë³„ ìˆ˜ìš” ì˜ˆì¸¡ ê°€ëŠ¥")
    
    print("\n3. ğŸ” í‚¤ì›Œë“œ ë¶„ì„ìš©:")
    print(f"   - {files['queries_file']} íŒŒì¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ ìµœì í™”")
    print("   - SEO ë° ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½")
    
    print("\n4. âœï¸ ì½˜í…ì¸  ì œì‘ìš©:")
    print(f"   - {files['prompts_file']} íŒŒì¼ë¡œ FAQ, ë¸”ë¡œê·¸ ì†Œì¬ í™•ë³´")
    print("   - ê³ ê° ìƒë‹´ ë§¤ë‰´ì–¼ ì‘ì„±")
    
    return {
        "prompts": prompts,
        "analysis": analysis,
        "files": files
    }

# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def generate_specific_category_prompts(category: str, num_prompts: int = 100):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ í”„ë¡¬í”„íŠ¸ ì§‘ì¤‘ ìƒì„±"""
    generator = MassivePromptGenerator()
    
    if category not in generator.dongrae_system.params.practice_areas:
        print(f"ì˜¤ë¥˜: '{category}'ëŠ” ìœ íš¨í•œ ë²•ë¬´ë¶„ì•¼ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë¶„ì•¼: {generator.dongrae_system.params.practice_areas}")
        return None
    
    print(f"=== {category} íŠ¹í™” í”„ë¡¬í”„íŠ¸ {num_prompts}ê°œ ìƒì„± ===")
    
    # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ í…œí”Œë¦¿ë§Œ ì‚¬ìš©
    category_templates = generator.expanded_query_templates.get(category, [])
    if not category_templates:
        print(f"'{category}' ì¹´í…Œê³ ë¦¬ì˜ í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    category_queries = []
    
    # í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
    for _ in range(num_prompts):
        template = random.choice(category_templates)
        query = template.format(
            action=random.choice(generator.template_variables["action"]),
            detail=random.choice(generator.template_variables["detail"]),
            metric=random.choice(generator.template_variables["metric"]),
            urgency=random.choice(generator.template_variables["urgency"]),
            region=random.choice(generator.template_variables["region"])
        )
        category_queries.append(query)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompts = []
    for i, query in enumerate(category_queries):
        result = generator.dongrae_system.generate_dongrae_prompt(query)
        result["sample_id"] = f"dongrae_{category}_{i+1:03d}"
        result["query"] = query
        prompts.append(result)
    
    # íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"dongrae_{category}_prompts_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(prompts, f, ensure_ascii=False, indent=2)
    
    print(f"{category} íŠ¹í™” í”„ë¡¬í”„íŠ¸ {len(prompts)}ê°œ ìƒì„± ì™„ë£Œ")
    print(f"íŒŒì¼ ì €ì¥: {filename}")
    
    return prompts

def generate_difficulty_prompts(difficulty: str, num_prompts: int = 100):
    """íŠ¹ì • ë‚œì´ë„ í”„ë¡¬í”„íŠ¸ ì§‘ì¤‘ ìƒì„±"""
    generator = MassivePromptGenerator()
    
    if difficulty not in ["ì‰¬ì›€", "ë³´í†µ", "ì–´ë ¤ì›€"]:
        print("ì˜¤ë¥˜: ë‚œì´ë„ëŠ” 'ì‰¬ì›€', 'ë³´í†µ', 'ì–´ë ¤ì›€' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return None
    
    print(f"=== '{difficulty}' ë‚œì´ë„ í”„ë¡¬í”„íŠ¸ {num_prompts}ê°œ ìƒì„± ===")
    
    # ë‚œì´ë„ë³„ íŠ¹í™” ì§ˆì˜ íŒ¨í„´
    difficulty_patterns = {
        "ì‰¬ì›€": [
            "{practice_area} ê´€ë ¨í•´ì„œ {metric}",
            "{region}ì—ì„œ {practice_area} {action}",
            "{practice_area} {detail} ì„œë¹„ìŠ¤ {metric}"
        ],
        "ë³´í†µ": [
            "{time_span} ê¸°ì¤€ìœ¼ë¡œ {region} {practice_area} {metric} {source_hint} ìë£Œ",
            "{practice_area} ë¶„ì•¼ì—ì„œ {detail} {metric} ë¹„êµë¶„ì„",
            "{region} ì§€ì—­ {practice_area} ì „ë¬¸ê°€ {metric} ê²€í† "
        ],
        "ì–´ë ¤ì›€": [
            "{source_hint} ë°ì´í„° ê¸°ë°˜ {time_span} {region} {practice_area} ì‹œì¥ {metric} ì¢…í•©ë¶„ì„",
            "ë³µí•©ì  {practice_area} ì‚¬ì•ˆì˜ {metric} ì „ëµì  ì ‘ê·¼ê³¼ {source_hint} ì—°ê³„ ê²€í† ",
            "{time_span} ë™ì•ˆ {region} {practice_area} ë¶„ì•¼ {metric} ê²½ìŸë ¥ ì§„ë‹¨ ë° ê°œì„ ë°©ì•ˆ"
        ]
    }
    
    patterns = difficulty_patterns[difficulty]
    queries = []
    
    for _ in range(num_prompts):
        pattern = random.choice(patterns)
        
        # íŒŒë¼ë¯¸í„° ê°•ì œ ì„¤ì •
        params = generator.dongrae_system.params.get_random_parameters()
        params["difficulty"] = difficulty
        
        query = pattern.format(
            practice_area=params["practice_area"],
            region=params["region"],
            metric=params["metric"],
            time_span=params.get("time_span", "ìµœê·¼3ë…„"),
            source_hint=params.get("source_hint", "ëŒ€í•œë³€í˜‘"),
            action=random.choice(generator.template_variables["action"]),
            detail=random.choice(generator.template_variables["detail"])
        )
        queries.append(query)
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompts = []
    for i, query in enumerate(queries):
        result = generator.dongrae_system.generate_dongrae_prompt(query)
        # ë‚œì´ë„ ê°•ì œ ì„¤ì •
        result["final_parameters"]["difficulty"] = difficulty
        result["sample_id"] = f"dongrae_{difficulty}_{i+1:03d}"
        result["query"] = query
        prompts.append(result)
    
    # íŒŒì¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"dongrae_{difficulty}_difficulty_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(prompts, f, ensure_ascii=False, indent=2)
    
    print(f"'{difficulty}' ë‚œì´ë„ í”„ë¡¬í”„íŠ¸ {len(prompts)}ê°œ ìƒì„± ì™„ë£Œ")
    print(f"íŒŒì¼ ì €ì¥: {filename}")
    
    return prompts

# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸš€ ë²•ë¬´ë²•ì¸ ë™ë˜ ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤!")
    print("\nì„ íƒí•˜ì„¸ìš”:")
    print("1. ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê¸°ë³¸ 1000ê°œ)")
    print("2. ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‚¬ìš©ì ì§€ì • ê°œìˆ˜)")
    print("3. íŠ¹ì • ë²•ë¬´ë¶„ì•¼ ì§‘ì¤‘ ìƒì„±")
    print("4. íŠ¹ì • ë‚œì´ë„ ì§‘ì¤‘ ìƒì„±")
    print("5. ëª¨ë“  ì˜µì…˜ ìë™ ì‹¤í–‰")
    
    choice = input("\në²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-5): ").strip()
    
    if choice == "1":
        # ê¸°ë³¸ 1000ê°œ ìƒì„±
        result = run_massive_generation(1000)
        
    elif choice == "2":
        # ì‚¬ìš©ì ì§€ì • ê°œìˆ˜
        try:
            num = int(input("ìƒì„±í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            result = run_massive_generation(num)
        except ValueError:
            print("ì˜ëª»ëœ ìˆ«ìì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ 1000ê°œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            result = run_massive_generation(1000)
            
    elif choice == "3":
        # íŠ¹ì • ë¶„ì•¼ ì§‘ì¤‘
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë²•ë¬´ë¶„ì•¼:")
        generator = MassivePromptGenerator()
        for i, area in enumerate(generator.dongrae_system.params.practice_areas, 1):
            print(f"  {i}. {area}")
        
        try:
            area_idx = int(input("\në²•ë¬´ë¶„ì•¼ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: ")) - 1
            area = generator.dongrae_system.params.practice_areas[area_idx]
            num = int(input("ìƒì„±í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            result = generate_specific_category_prompts(area, num)
        except (ValueError, IndexError):
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
            
    elif choice == "4":
        # íŠ¹ì • ë‚œì´ë„ ì§‘ì¤‘
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë‚œì´ë„:")
        print("  1. ì‰¬ì›€")
        print("  2. ë³´í†µ") 
        print("  3. ì–´ë ¤ì›€")
        
        try:
            diff_choice = int(input("\në‚œì´ë„ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”: "))
            difficulties = ["ì‰¬ì›€", "ë³´í†µ", "ì–´ë ¤ì›€"]
            difficulty = difficulties[diff_choice - 1]
            num = int(input("ìƒì„±í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”: "))
            result = generate_difficulty_prompts(difficulty, num)
        except (ValueError, IndexError):
            print("ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
            
    elif choice == "5":
        # ëª¨ë“  ì˜µì…˜ ìë™ ì‹¤í–‰
        print("ğŸ¯ ëª¨ë“  ì˜µì…˜ ìë™ ì‹¤í–‰ ì‹œì‘!")
        
        # 1. ëŒ€ëŸ‰ ìƒì„± (500ê°œ)
        print("\n1ï¸âƒ£ ëŒ€ëŸ‰ í”„ë¡¬í”„íŠ¸ ìƒì„± (500ê°œ)")
        run_massive_generation(500)
        
        # 2. ì£¼ìš” ë¶„ì•¼ë³„ ìƒì„± (ê° 50ê°œ)
        major_areas = ["ê¸°ì—…ë²•ë¬´", "ë¶€ë™ì‚°ë²•ë¬´", "í˜•ì‚¬ë²•ë¬´", "ë…¸ë™ë²•ë¬´", "ê³„ì•½ë²•ë¬´"]
        for area in major_areas:
            print(f"\n2ï¸âƒ£ {area} íŠ¹í™” ìƒì„± (50ê°œ)")
            generate_specific_category_prompts(area, 50)
        
        # 3. ë‚œì´ë„ë³„ ìƒì„± (ê° 30ê°œ)
        for difficulty in ["ì‰¬ì›€", "ë³´í†µ", "ì–´ë ¤ì›€"]:
            print(f"\n3ï¸âƒ£ '{difficulty}' ë‚œì´ë„ ìƒì„± (30ê°œ)")
            generate_difficulty_prompts(difficulty, 30)
        
        print("\nğŸ‰ ëª¨ë“  ì˜µì…˜ ì‹¤í–‰ ì™„ë£Œ!")
        print("ì´ ìƒì„±ëŸ‰: ëŒ€ëŸ‰ 500ê°œ + ë¶„ì•¼ë³„ 250ê°œ + ë‚œì´ë„ë³„ 90ê°œ = 840ê°œ")
        
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        result = run_massive_generation(1000)
    
    print("\nâœ… í”„ë¡¬í”„íŠ¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("ìƒì„±ëœ íŒŒì¼ë“¤ì„ í™•ì¸í•´ë³´ì„¸ìš”.")
    print("\nğŸ“ íŒŒì¼ í™œìš©ë²•:")
    print("- JSON íŒŒì¼: AI í›ˆë ¨/API ì—°ë™ìš©")
    print("- TXT íŒŒì¼: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœ")
    print("- CSV íŒŒì¼: ì—‘ì…€ì—ì„œ ë¶„ì„ ê°€ëŠ¥")